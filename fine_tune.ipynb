{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\djbac\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1000 examples [00:00, 17972.15 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 3617.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV dataset\n",
    "# Can't specify split because the dataset has not been divided to train and test yet\n",
    "# So everything is loaded to \"train\"\n",
    "dataset = load_dataset('csv', data_files='./datasets/youtoxic_english_1000.csv')\n",
    "\n",
    "# Define a function to do some preprocessing - rename target and map values\n",
    "# I'll rename the target column \"IsToxic\" to \"labels\".\n",
    "def preprocess_data(data):\n",
    "    # Rename columns    \n",
    "    data['labels'] = data.pop('IsToxic')\n",
    "    data['text'] = data.pop('Text')\n",
    "    # Map true/false to 1/0\n",
    "    data['labels'] = 1 if data['labels'] == True else 0\n",
    "    return data\n",
    "\n",
    "# Run the preprocessing\n",
    "dataset = dataset.map(preprocess_data)\n",
    "\n",
    "# Split the dataset into train-test\n",
    "dict_train_test_split = dataset[\"train\"].train_test_split(test_size=0.2, seed=823)\n",
    "\n",
    "# Access the train and test sets\n",
    "dict_train = dict_train_test_split[\"train\"]\n",
    "dict_test = dict_train_test_split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Use the Pretrained Network directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize the Tokenizer and the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\djbac\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Can also do this\n",
    "# Initialize tokenizer and model\n",
    "model = \"martin-ha/toxic-comment-model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model)  # Adjust num_labels as needed\n",
    "classifier = TextClassificationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Use pipeline(task=\"text-classification\") for simplicity and ease of use, especially for standard tasks where you don't need much customization.\n",
    "# Use TextClassificationPipeline when you need more control over the pipeline components or when you're working on a more complex or customized task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test = dict_test['text']\n",
    "actual_labels = dict_test[\"labels\"]\n",
    "# Make predictions\n",
    "predictions = classifier(inputs_test)\n",
    "# Predicted labels are \"non-toxic\" and \"toxic\", so we still need to map that\n",
    "label_mapping = {\"non-toxic\": 0, \"toxic\": 1}\n",
    "predicted_labels = [label_mapping[pred['label']] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.78       118\n",
      "           1       0.70      0.51      0.59        82\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.71      0.68      0.68       200\n",
      "weighted avg       0.71      0.71      0.70       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(classification_report(actual_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### (2) Perform Finetuning using the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 200/200 [00:00<00:00, 2347.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "# Here is where you specify the input column\n",
    "def tokenize_function(input_string):\n",
    "    return tokenizer(input_string['text'], padding='max_length', truncation=True, truncation_strategy='longest_first')\n",
    "\n",
    "# Apply the tokenization function to your dataset\n",
    "dict_train_tokenized = dict_train.map(tokenize_function, batched=True)\n",
    "dict_test_tokenized = dict_test.map(tokenize_function, batched=True)\n",
    "\n",
    "# Format dataset for PyTorch\n",
    "# Here is where you specify the label/target column\n",
    "dict_train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "dict_test_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',              # Directory to save results\n",
    "    num_train_epochs=5,                  # Number of training epochs\n",
    "    per_device_train_batch_size=16,      # Batch size per device during training\n",
    "    per_device_eval_batch_size=32,       # Batch size per device during evaluation\n",
    "    warmup_steps=500,                   # Number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                  # Strength of weight decay\n",
    "    logging_dir='./logs',               # Directory for storing logs\n",
    "    logging_steps=10,                   # Frequency of logging steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                          # The model to train\n",
    "    args=training_args,                   # Training arguments\n",
    "    train_dataset=dict_train_tokenized,        # The dataset to train on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not read Jupyter Notebook: No module named 'nbconvert'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: overwriting (reusing) task id=9e614809235d475da9b542269ae68b6b\n",
      "ClearML results page: https://app.clear.ml/projects/a280739eaca04ea6b7be4b98665e026b/experiments/9e614809235d475da9b542269ae68b6b/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameters must be of builtin type (Transformers/accelerator_config[AcceleratorConfig])\n",
      "  4%|▍         | 10/250 [00:50<20:30,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9165, 'grad_norm': 6.543761253356934, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20/250 [01:41<19:31,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0359, 'grad_norm': 90.1664047241211, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30/250 [02:33<18:42,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7416, 'grad_norm': 26.681711196899414, 'learning_rate': 3e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 40/250 [03:20<16:33,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8805, 'grad_norm': 14.477645874023438, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 50/250 [04:08<15:44,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8904, 'grad_norm': 12.889693260192871, 'learning_rate': 5e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 60/250 [05:08<20:18,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7475, 'grad_norm': 4.488498210906982, 'learning_rate': 6e-06, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 70/250 [06:10<17:23,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6863, 'grad_norm': 12.406845092773438, 'learning_rate': 7.000000000000001e-06, 'epoch': 1.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 80/250 [07:11<15:19,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6392, 'grad_norm': 15.060066223144531, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 90/250 [08:13<15:48,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5373, 'grad_norm': 34.87422561645508, 'learning_rate': 9e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 100/250 [09:03<12:16,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7311, 'grad_norm': 140.96536254882812, 'learning_rate': 1e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 110/250 [09:53<11:21,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6792, 'grad_norm': 40.50693130493164, 'learning_rate': 1.1000000000000001e-05, 'epoch': 2.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 120/250 [10:42<10:32,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6006, 'grad_norm': 83.99149322509766, 'learning_rate': 1.2e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 130/250 [11:32<09:44,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5875, 'grad_norm': 4.254546165466309, 'learning_rate': 1.3000000000000001e-05, 'epoch': 2.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 140/250 [12:23<09:42,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7433, 'grad_norm': 1.8301067352294922, 'learning_rate': 1.4000000000000001e-05, 'epoch': 2.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 150/250 [13:23<08:53,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7007, 'grad_norm': 120.06061553955078, 'learning_rate': 1.5e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 160/250 [14:13<07:18,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6134, 'grad_norm': 24.287200927734375, 'learning_rate': 1.6000000000000003e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 170/250 [15:02<06:29,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5933, 'grad_norm': 16.255552291870117, 'learning_rate': 1.7000000000000003e-05, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 180/250 [15:52<05:41,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6495, 'grad_norm': 186.526123046875, 'learning_rate': 1.8e-05, 'epoch': 3.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 190/250 [16:42<04:52,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6692, 'grad_norm': 25.667909622192383, 'learning_rate': 1.9e-05, 'epoch': 3.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 200/250 [17:32<04:03,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6484, 'grad_norm': 24.13962173461914, 'learning_rate': 2e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 210/250 [18:21<03:14,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6153, 'grad_norm': 8.585556983947754, 'learning_rate': 2.1e-05, 'epoch': 4.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 220/250 [19:11<02:25,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6443, 'grad_norm': 19.688703536987305, 'learning_rate': 2.2000000000000003e-05, 'epoch': 4.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 230/250 [20:01<01:37,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5958, 'grad_norm': 5.147881031036377, 'learning_rate': 2.3000000000000003e-05, 'epoch': 4.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 240/250 [20:50<00:48,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6791, 'grad_norm': 26.59487533569336, 'learning_rate': 2.4e-05, 'epoch': 4.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [21:40<00:00,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5958, 'grad_norm': 6.926318645477295, 'learning_rate': 2.5e-05, 'epoch': 5.0}\n",
      "{'train_runtime': 1328.4035, 'train_samples_per_second': 3.011, 'train_steps_per_second': 0.188, 'train_loss': 0.6968718776702881, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [21:45<00:00,  5.22s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.6968718776702881, metrics={'train_runtime': 1328.4035, 'train_samples_per_second': 3.011, 'train_steps_per_second': 0.188, 'total_flos': 529869594624000.0, 'train_loss': 0.6968718776702881, 'epoch': 5.0})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:26<00:00,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.6941024661064148, 'eval_runtime': 26.4832, 'eval_samples_per_second': 7.552, 'eval_steps_per_second': 0.264, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "eval_results = trainer.evaluate(eval_dataset=dict_test_tokenized)\n",
    "print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:50<00:00, 12.68s/it]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions, labels, _ = trainer.predict(test_dataset=dict_test_tokenized)\n",
    "# Convert predictions to labels (optional, depending on your task)\n",
    "predicted_labels = predictions.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       118\n",
      "           1       0.59      0.43      0.50        82\n",
      "\n",
      "    accuracy                           0.65       200\n",
      "   macro avg       0.63      0.61      0.61       200\n",
      "weighted avg       0.64      0.65      0.63       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets\\mtsamples.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering to 12 classes for simplicity\n",
    "list_med_sp = [\n",
    "    \" Allergy / Immunology\",\n",
    "    \" Bariatrics\",\n",
    "    \" Cardiovascular / Pulmonary\",\n",
    "    \" Urology\",\n",
    "    \" Dentistry\",\n",
    "    \" Rheumatology\",\n",
    "    \" Radiology\",\n",
    "    \" Psychiatry / Psychology\",\n",
    "    \" Podiatry\",\n",
    "    \" Orthopedic\",\n",
    "    \" Opthalmology\",\n",
    "    \" Neurology\"\n",
    "]\n",
    "# Filter the DataFrame\n",
    "df = df[df['medical_specialty'].isin(list_med_sp)]\n",
    "\n",
    "# df_stratified, _ = train_test_split(df, train_size=0.03, stratify=df['medical_specialty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the candidate labels for the ZSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_labels = df[\"medical_specialty\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = (\n",
    "    pipeline(task=\"zero-shot-classification\",\n",
    "             model=\"tasksource/deberta-small-long-nli\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify a single description\n",
    "def classify_description(description):\n",
    "    result = classifier(description, candidate_labels)\n",
    "    # Find the index of the maximum score\n",
    "    max_index = result['scores'].index(max(result['scores']))\n",
    "    # Return the label with the highest score\n",
    "    return result['labels'][max_index], result['scores'][max_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|██████████| 1543/1543 [49:52<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "df[['zero_shot_class', 'score']] = (\n",
    "    df['description']\n",
    "    .swifter.progress_bar(enable=True)\n",
    "    .apply(classify_description)  # Apply function directly\n",
    "    .apply(pd.Series)  # Convert tuple/list output into DataFrame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53\n",
      "Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "       Allergy / Immunology       0.16      1.00      0.27         7\n",
      "                 Bariatrics       0.75      0.83      0.79        18\n",
      " Cardiovascular / Pulmonary       0.81      0.23      0.36       372\n",
      "                  Dentistry       0.76      0.81      0.79        27\n",
      "                  Neurology       0.71      0.31      0.44       223\n",
      "                 Orthopedic       0.71      0.74      0.72       355\n",
      "                   Podiatry       0.55      0.38      0.45        47\n",
      "    Psychiatry / Psychology       0.78      0.74      0.76        53\n",
      "                  Radiology       0.31      0.76      0.44       273\n",
      "               Rheumatology       0.18      0.40      0.25        10\n",
      "                    Urology       0.93      0.59      0.73       158\n",
      "\n",
      "                   accuracy                           0.53      1543\n",
      "                  macro avg       0.60      0.62      0.54      1543\n",
      "               weighted avg       0.68      0.53      0.53      1543\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  7   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  15   0   0   0   1   0   0   2   0   0]\n",
      " [ 21   3  87   2   8  24   0   1 217   8   1]\n",
      " [  0   0   0  22   0   5   0   0   0   0   0]\n",
      " [  2   1   2   2  70  23   2  10 107   3   1]\n",
      " [  4   0   0   0   4 261  10   0  73   2   1]\n",
      " [  1   0   0   0   0  23  18   0   5   0   0]\n",
      " [  1   0   0   0   5   0   0  39   4   2   2]\n",
      " [  3   1  19   2  10  23   3   0 208   2   2]\n",
      " [  3   0   0   0   0   3   0   0   0   4   0]\n",
      " [  3   0   0   1   1   5   0   0  53   1  94]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Assuming 'y_true' is the actual label and 'y_pred' is the predicted label\n",
    "y_true = df['medical_specialty']\n",
    "y_pred = df['zero_shot_class']\n",
    "\n",
    "# Get accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Get classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Get confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
